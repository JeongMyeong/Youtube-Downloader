{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install konlpy\n",
    "# !pip install gensim\n",
    "# !pip install fasttext\n",
    "# import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "1.13.2\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "import tensorflow\n",
    "print(keras.__version__)\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from gensim.models import Word2Vec\n",
    "# from gensim.models import FastText\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def delete_emoji(sentence):\n",
    "    try:\n",
    "        hangul = re.compile('[^ ㄱ-ㅣ가-힣A-Za-z0-9]+') # 한글과 띄어쓰기를 제외한 모든 글자\n",
    "        result = hangul.sub('', sentence) # 한글과 띄어쓰기를 제외한 모든 부분을 제거\n",
    "#         result.replace('\\n',' ')\n",
    "        return result\n",
    "    except:\n",
    "        print(sentence)\n",
    "        return ' '\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('data/except_moviereviews.csv')\n",
    "df2 = pd.read_csv('data/except_moviereviews_20191107.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1795, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    930\n",
       "2    806\n",
       "3    781\n",
       "Name: subject, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "2390\n",
      "2400\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "2440\n",
      "2450\n",
      "2460\n",
      "2470\n",
      "2480\n",
      "2490\n",
      "2500\n",
      "2510\n",
      "Wall time: 1h 16min 4s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "title=[]\n",
    "for idx, url in enumerate(list(df['url'])):\n",
    "    if idx%10==0:\n",
    "        print(idx)\n",
    "    target_html = 'https://www.youtube.com{}'.format(url)\n",
    "    html = urllib.request.urlopen(target_html).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    title.append(soup.find('title').text[:-10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['title']=title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>subject</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/watch?v=vdCSoJ8w4hk</td>\n",
       "      <td>1</td>\n",
       "      <td>칼리스타 창으로 아군 서포터 죽여버림ㅋㅋㅋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/watch?v=0z0gj6BUmD8</td>\n",
       "      <td>1</td>\n",
       "      <td>맨날 화나있던 그가 서폿칭찬을 한 이유【천상계 랭겜】</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/watch?v=xTTZGtgL5OA</td>\n",
       "      <td>1</td>\n",
       "      <td>아군 정글러에게 매운맛을 보여줬습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/watch?v=6TSiO7Y0p2A</td>\n",
       "      <td>1</td>\n",
       "      <td>지금 바루스를 해야하는 이유. \"숨은 꿀챔\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/watch?v=C30FhUGTVnY</td>\n",
       "      <td>1</td>\n",
       "      <td>극한의 이득을위해 일부러(?) 죽는 이즈리얼</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    url  subject                          title\n",
       "0  /watch?v=vdCSoJ8w4hk        1        칼리스타 창으로 아군 서포터 죽여버림ㅋㅋㅋ\n",
       "1  /watch?v=0z0gj6BUmD8        1  맨날 화나있던 그가 서폿칭찬을 한 이유【천상계 랭겜】\n",
       "2  /watch?v=xTTZGtgL5OA        1          아군 정글러에게 매운맛을 보여줬습니다.\n",
       "3  /watch?v=6TSiO7Y0p2A        1       지금 바루스를 해야하는 이유. \"숨은 꿀챔\"\n",
       "4  /watch?v=C30FhUGTVnY        1       극한의 이득을위해 일부러(?) 죽는 이즈리얼"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('title_label_except_moviereviews_20191107.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('title_label_except_moviereviews_20191107_2.csv')\n",
    "df.dropna(inplace=True)\n",
    "# df2 = pd.read_csv('data/title_label2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    915\n",
       "2    788\n",
       "3    741\n",
       "Name: subject, dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2444, 3)\n",
      "(2444, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove=[]\n",
    "# for idx, i in enumerate(list(df['title'])[:100]):\n",
    "#     subject = list(df['subject'])[idx]\n",
    "#     if subject==1:\n",
    "#         s='게임'\n",
    "#     elif subject==2:\n",
    "#         s='노래'\n",
    "#     elif subject==3:\n",
    "#         s='IT'\n",
    "#     elif subject==4:\n",
    "#         s='영화'\n",
    "#     print(\"[{}] {}\".format(s,i))\n",
    "#     r = input()\n",
    "#     if r=='1':\n",
    "#         remove.append(1)\n",
    "#     else:\n",
    "#         remove.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = df.loc[ ((df['subject'] == 1) | (df['subject']==2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tagger = Okt()\n",
    "sentences = list(df['title'])\n",
    "sentences = [delete_emoji(sentence) for sentence in sentences]\n",
    "sentences_Okt = []\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    sen_okt = tagger.morphs(sentence)\n",
    "    sentences_Okt.append(sen_okt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec_model = Word2Vec(sentences=sentences_Okt, size=300, window=4, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim import models\n",
    "# models.fast\n",
    "# cap_path = datapath(\"C:/Users/JeongMyeong/Desktop/word-embeddings/fasttext/fasttext.bin\")\n",
    "fb_model = models.fasttext.load_facebook_model('C:/Users/JeongMyeong/Desktop/word-embeddings/fasttext/fasttext.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec.load('C:/Users/JeongMyeong/Desktop/word-embeddings/word2vec/word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.joblib import dump, load\n",
    "def vectorize(model, sentences):\n",
    "  \n",
    "    result = []\n",
    "    for idx, sentence in enumerate(sentences):\n",
    "        tmp = []\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                tmp.append(model.wv.word_vec(word))\n",
    "            except:\n",
    "                pass\n",
    "        if tmp==[]:\n",
    "            print(sentence)\n",
    "            result.append(np.zeros((model.wv.vector_size, ),dtype='float32'))\n",
    "        else:\n",
    "            result.append(sum(tmp)/len(tmp)) \n",
    "    return np.array(result)\n",
    "\n",
    "\n",
    "def scaler_transform(train, test): # , valid, test):\n",
    "    scaler = StandardScaler()\n",
    "#     scaler = load('std_scaler.bin')\n",
    "    train_scale = scaler.fit_transform(train)\n",
    "#     valid_scale = scaler.transform(valid)\n",
    "    test_scale = scaler.transform(test)\n",
    "    dump(scaler, 'std_scaler_20191107.bin', compress=True)\n",
    "    return train_scale, test_scale # valid_scale, test_scale\n",
    "\n",
    "def score(prediction, label):\n",
    "    prediction = [1 if p>0.5 else 0 for p in prediction]\n",
    "    return accuracy_score(prediction, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentences_Okt, df['subject'], test_size=0.3, random_state=42)\n",
    "X_train_vec = vectorize(fb_model, X_train)\n",
    "# X_valid_vec = vectorize(word2vec_model, X_valid_Okt)\n",
    "X_test_vec = vectorize(fb_model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = fb_model.wv.vector_size\n",
    "vocab = len(fb_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "X_train_scale, X_test_scale = scaler_transform(X_train_vec, X_test_vec)\n",
    "y_train_category = [i-1 for i in y_train]\n",
    "y_test_category = [i-1 for i in y_test]\n",
    "y_train_category = keras.utils.np_utils.to_categorical(y_train_category, num_classes=3)\n",
    "y_test_category = keras.utils.np_utils.to_categorical(y_test_category, num_classes=3)\n",
    "\n",
    "X_train_scale, X_valid_scale, y_train_category, y_valid_category = train_test_split(X_train_scale, y_train_category, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Model \n",
    "from keras.layers import Flatten, Dropout,Conv2D, concatenate,Conv1D, MaxPooling1D,Dense, Embedding, LSTM, Input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "# import tensorflow as tf\n",
    "# run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "\n",
    "\n",
    "input_sentence = Input(shape=(dim,))\n",
    "emb = Embedding(vocab+1, 32, input_length=dim)(input_sentence)\n",
    "drop = Dropout(0.3)(emb)\n",
    "conv = Conv1D(3,3, padding='valid', activation='relu')(drop)\n",
    "maxpool = MaxPooling1D(pool_size=1)(conv)\n",
    "flat = Flatten()(maxpool)\n",
    "hidden = Dense(16, activation='relu')(flat)\n",
    "drop = Dropout(0.5)(hidden)\n",
    "output = Dense(3, activation='softmax')(drop)\n",
    "cnn_model = Model(input_sentence, output)\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])#, options = run_opts)\n",
    "early_stopping  = EarlyStopping()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1453 samples, validate on 257 samples\n",
      "Epoch 1/30\n",
      "1453/1453 [==============================] - 1s 479us/step - loss: 1.0978 - accuracy: 0.3565 - val_loss: 1.0948 - val_accuracy: 0.4047\n",
      "Epoch 2/30\n",
      "1453/1453 [==============================] - 0s 131us/step - loss: 1.0911 - accuracy: 0.3944 - val_loss: 1.0774 - val_accuracy: 0.5253\n",
      "Epoch 3/30\n",
      "1453/1453 [==============================] - 0s 131us/step - loss: 1.0630 - accuracy: 0.4639 - val_loss: 1.0090 - val_accuracy: 0.5992\n",
      "Epoch 4/30\n",
      "1453/1453 [==============================] - 0s 136us/step - loss: 0.9693 - accuracy: 0.5733 - val_loss: 0.8139 - val_accuracy: 0.7432\n",
      "Epoch 5/30\n",
      "1453/1453 [==============================] - 0s 133us/step - loss: 0.7822 - accuracy: 0.6889 - val_loss: 0.5753 - val_accuracy: 0.8366\n",
      "Epoch 6/30\n",
      "1453/1453 [==============================] - 0s 131us/step - loss: 0.6341 - accuracy: 0.7715 - val_loss: 0.4315 - val_accuracy: 0.8833\n",
      "Epoch 7/30\n",
      "1453/1453 [==============================] - 0s 133us/step - loss: 0.5451 - accuracy: 0.8011 - val_loss: 0.3565 - val_accuracy: 0.8755\n",
      "Epoch 8/30\n",
      "1453/1453 [==============================] - 0s 135us/step - loss: 0.4847 - accuracy: 0.8314 - val_loss: 0.3132 - val_accuracy: 0.8872\n",
      "Epoch 9/30\n",
      "1453/1453 [==============================] - 0s 131us/step - loss: 0.4481 - accuracy: 0.8486 - val_loss: 0.2917 - val_accuracy: 0.9105\n",
      "Epoch 10/30\n",
      "1453/1453 [==============================] - 0s 132us/step - loss: 0.4327 - accuracy: 0.8582 - val_loss: 0.2916 - val_accuracy: 0.8988\n",
      "Epoch 11/30\n",
      "1453/1453 [==============================] - 0s 131us/step - loss: 0.4146 - accuracy: 0.8658 - val_loss: 0.2713 - val_accuracy: 0.8988\n",
      "Epoch 12/30\n",
      "1453/1453 [==============================] - 0s 133us/step - loss: 0.3858 - accuracy: 0.8734 - val_loss: 0.2509 - val_accuracy: 0.9144\n",
      "Epoch 13/30\n",
      "1453/1453 [==============================] - 0s 131us/step - loss: 0.3891 - accuracy: 0.8692 - val_loss: 0.2490 - val_accuracy: 0.9027\n",
      "Epoch 14/30\n",
      "1453/1453 [==============================] - 0s 135us/step - loss: 0.3742 - accuracy: 0.8796 - val_loss: 0.2421 - val_accuracy: 0.9183\n",
      "Epoch 15/30\n",
      "1453/1453 [==============================] - 0s 131us/step - loss: 0.3420 - accuracy: 0.8864 - val_loss: 0.2337 - val_accuracy: 0.9144\n",
      "Epoch 16/30\n",
      "1453/1453 [==============================] - 0s 132us/step - loss: 0.3537 - accuracy: 0.8933 - val_loss: 0.2278 - val_accuracy: 0.9183\n",
      "Epoch 17/30\n",
      "1453/1453 [==============================] - 0s 132us/step - loss: 0.3380 - accuracy: 0.8796 - val_loss: 0.2213 - val_accuracy: 0.9144\n",
      "Epoch 18/30\n",
      "1453/1453 [==============================] - 0s 131us/step - loss: 0.3420 - accuracy: 0.8727 - val_loss: 0.2253 - val_accuracy: 0.9144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d8d2480c88>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(X_train_scale,y_train_category, \n",
    "            batch_size=32, \n",
    "            epochs=30, \n",
    "            callbacks=[early_stopping],\n",
    "            validation_data=(X_valid_scale, y_valid_category)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save('classification_three_20191107.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = cnn_model.predict(X_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69.11544 , 16.151625, 14.732938], dtype=float32)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[17]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=[]\n",
    "for i in range(len(X_test_scale)):\n",
    "    tt = list(predict[i])\n",
    "    prediction.append(tt.index(max(tt)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = keras.utils.np_utils.to_categorical(prediction, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9100817438692098"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(prediction, y_test_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(prediction, axis=1).reshape(-1,1)\n",
    "y_test_category_argmax = np.argmax(y_test_category, axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[265,  13,  10],\n",
       "       [  9, 208,   6],\n",
       "       [ 23,   5, 195]], dtype=int64)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 게임, 음악, IT\n",
    "confusion_matrix(pred, y_test_category_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[270,  19,  23],\n",
       "       [  8, 201,  10],\n",
       "       [ 19,   6, 178]], dtype=int64)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 게임, 음악, IT\n",
    "confusion_matrix(pred, y_test_category_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['대', '도서관', 'PS', 'VR', '으악', '상어', '가', '나타났다', 'VR', '월드', '오션', '디센트', 'PS', 'VR', 'Worlds', 'Ocean', 'Descent'] [2] [0]\n",
      "['룰러', '의', '역', '관광', '무빙', '원딜', '룰러', '11월', '롤', '매드무비', 'GEN', 'G', 'Ruler', 'Montage'] [2] [0]\n",
      "['대통령', '경호', '하기', '게임', '대', '도서관', '코믹', '실황', '1', '화', 'Mr', 'President'] [2] [0]\n",
      "['진짜', '말', '도', '안되는', '옵션', '이', '떠', '버렸습니다', '팡', '이요', '메이플스토리'] [2] [0]\n",
      "['코브', '4', 'K', 'ㅣ', '세계', '최강', '의', '그래픽', '을', '가진', '게임', 'TOP', '10', '파트', '1'] [2] [0]\n",
      "['신규', '빠칭코', '1등', '당첨', '됐다', 'ㄷㄷ', '마일리지', '상품', '까지', '몸빵', '현질', '피파', '4'] [2] [0]\n",
      "['도적', '전', '직업', '5초', '쿨', '감모', '자', '성능', '실험', '해봤습니다', '메이플스토리', '후니'] [2] [0]\n",
      "['정글', '동선', '설계', '법', '강의', '정글', '심화', '분석', '동선', '낭비', '0', '챌', '린', '저', '마스터', '동선', '설계', '패턴', '분석', '롤', '정글', '운영', '법라', '인', '비중', '라인', '이해', '라인', '흐름', '구간', '별', '예측'] [2] [0]\n",
      "['급발진', '역대', '급', '김여사', '주차', '된', '포르쉐', '차량', '박살', 'CCTV', '영상', '확보'] [2] [0]\n",
      "['역대', '급', '탑신', '병자', '를', '만났습니다'] [2] [0]\n",
      "['Chovy', '조이', '관전', '을', '통해', '배우는', '미드', '라이너', '기본', '소양', '분당', 'cs', '9', '는', '어떻게', '나오는', '걸까'] [2] [0]\n",
      "['승', '꼬얌', '썬', '콜', '의', '모든', '것', '을', '알아보자', '메이플스토리'] [2] [0]\n",
      "['가스', '최적화', '실전', '에서', '쓰는', '방법', '근데', '토스', '는', '안된다구요'] [2] [0]\n",
      "['아', '탑신', '병자', '클립', '수출', '당', '한', '옥자', '수치사', '하이라이트', 'ㅣ', '수치사', '하이라이트', '박', '옥자', '누나', '유튜브'] [2] [0]\n",
      "['데스티니', '3', '레벨', '탑', '로밍', '으로', '게임', '을', '터', '트리', '는', '서포터', '가', '있다', '챌', '린', '저', '구간', '바드', '플레이'] [2] [0]\n",
      "['iQ', '999', '원', '딜러', '의', '상점', '컨'] [2] [0]\n",
      "['공감', '100', '탑', '라이너', '들', '이', '강등', '당하는', '이유', '너', '무심', '한', '기도', '메타'] [2] [0]\n",
      "['저', '콜옵', '손', '절하', '겠습니다'] [2] [0]\n",
      "['CCTV', '로', '감시', '하는', '공포', '게임'] [2] [0]\n",
      "['뜨', '뜨', '뜨', '뜨', '입장', '표명'] [2] [0]\n",
      "['이제', '는', '구', '하지', '못', '하는', '한정판', '스킨', 'TOP', '5', '꿀잼', '랭크쇼', '오버', '워치', '롤큐'] [2] [0]\n",
      "['서든어택', '헤드', '슈터', '흑', '두', '3', '보급', '매드무비', '댓글', '이벤트'] [2] [0]\n",
      "['롤드컵', '4', '강', 'IG', 'vs', 'FPX', '초', '간단', '리뷰'] [2] [0]\n",
      "23 734\n",
      "0.031335149863760216\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for idx, (predict, label) in enumerate(zip(pred, y_test_category_argmax)):\n",
    "    if predict==2 and label==0:\n",
    "        print(X_test[idx], predict, label)\n",
    "        cnt+=1\n",
    "print(cnt, len(y_test_category))\n",
    "print(cnt/len(y_test_category))\n",
    "\n",
    "# 게임, 음악, IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8102665146796905542\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6600259666\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13732534684489279877\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:07:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
